{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXFJeKgAf6s1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install git+https://github.com/irhum/hyena.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVW2g7oxcr_u"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcnjghLFcr_y"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEHC7W1ocr_y"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import urllib.request\n",
        "\n",
        "# download the Shakespeare dataset\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = urllib.request.urlopen(url)\n",
        "text = response.read().decode(\"utf-8\")\n",
        "\n",
        "# preprocess the data\n",
        "vocab = sorted(set(text))\n",
        "char2idx = {c: i for (i, c) in enumerate(vocab)}\n",
        "idx2char = {i: c for (i, c) in enumerate(vocab)}\n",
        "tokens = jnp.array([char2idx[c] for c in text])\n",
        "\n",
        "split_idx = int(0.9*len(tokens))\n",
        "train, test = tokens[:split_idx], tokens[split_idx:]\n",
        "\n",
        "\n",
        "# function to generate a single batch of data\n",
        "def batch_gen(key, data, seq_len, batch_size):\n",
        "    idxs = jax.random.choice(\n",
        "        key, len(data) - seq_len - 1, shape=(batch_size,), replace=False\n",
        "    )\n",
        "    tok_idxs = jnp.array(idxs)[:, jnp.newaxis] + jnp.arange(seq_len)\n",
        "    input_tokens = data[tok_idxs]\n",
        "    target_tokens = data[tok_idxs + 1]\n",
        "    return input_tokens, target_tokens\n",
        "\n",
        "\n",
        "# function to generate batches upto a total number of tokens\n",
        "def dataset(key, data, seq_len, batch_size, total_tokens):\n",
        "    used_tokens = 0\n",
        "    while used_tokens < total_tokens:\n",
        "        key, _ = jax.random.split(key)\n",
        "        yield batch_gen(key, data, seq_len, batch_size)\n",
        "        used_tokens += batch_size * seq_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQVH1OYEQdNR"
      },
      "source": [
        "### Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9mEgi5wfWYR"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import flax.linen as nn\n",
        "\n",
        "from hyena import hyena, decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifzd7axyf_Av"
      },
      "outputs": [],
      "source": [
        "# NETWORK\n",
        "n_dim = 128\n",
        "n_layers = 6\n",
        "\n",
        "siren = partial(hyena.Siren, hidden_features=64, num_layers=4, freq=300.0)\n",
        "mixer = partial(\n",
        "    hyena.HyenaOperator, max_len=512, filter_fn=siren, modulation_fn=hyena.ExponentialModulation\n",
        ")\n",
        "layer = partial(\n",
        "    decoder.DecoderLayer,\n",
        "    features=n_dim,\n",
        "    hidden_features=n_dim * 4,\n",
        "    mixer_fn=mixer,\n",
        "    out_init=nn.initializers.normal(stddev=0.02 / jnp.sqrt(2*n_layers)),\n",
        ")\n",
        "embed_fn = partial(nn.Embed, num_embeddings=65, features=n_dim, embedding_init=nn.initializers.normal(stddev=0.02))\n",
        "m = decoder.Decoder(\n",
        "    embedding=embed_fn(), block_fn=layer, num_layers=n_layers,\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "key = jax.random.PRNGKey(2)\n",
        "p_key, d_key = jax.random.split(key)\n",
        "x = jax.random.randint(key, (1, 256), minval=0, maxval=65)\n",
        "params = m.init({\"params\": p_key, \"dropout\": d_key}, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuTF-1gbQymw"
      },
      "outputs": [],
      "source": [
        "import optax\n",
        "from flax import traverse_util\n",
        "from flax.core import frozen_dict\n",
        "\n",
        "# OPTIMIZER\n",
        "# we create a weight decay mask, to apply only to kernels (not biases)\n",
        "def wd_mask(params):\n",
        "    mask = traverse_util.flatten_dict(params, sep=\"/\")\n",
        "    mask = {k: k.endswith(\"kernel\") for k in mask}\n",
        "    mask = traverse_util.unflatten_dict(mask, sep=\"/\")\n",
        "    return frozen_dict.freeze(mask)\n",
        "\n",
        "# we create an optimizer with weight decay\n",
        "sched = optax.warmup_cosine_decay_schedule(init_value=1e-4,\n",
        "  peak_value=1e-3,\n",
        "  warmup_steps=100,\n",
        "  decay_steps=5000,\n",
        "  end_value=1e-4,\n",
        ")\n",
        "opt = optax.chain(optax.clip_by_global_norm(1.0),\n",
        "                  optax.adamw(sched, weight_decay=0.1, mask=wd_mask, b2=0.99))\n",
        "opt_state = opt.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBdq2CySVWd3",
        "outputId": "19c0047e-2728-4304-e991-4bf2d9ad5336"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1510016"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Parameter Count\n",
        "jax.tree_util.tree_reduce(lambda x, y: x + y, jax.tree_map(lambda x: x.size, params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZXdZ_azcr_z"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duZKjUqhgAEv",
        "outputId": "583f3912-7a4b-4c28-9211-95816ff88e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.1729574 Iteration 0: Validation loss: 4.153886795043945\n",
            "2.5329142 Iteration 250: Validation loss: 2.529892683029175\n",
            "1.8411844 Iteration 500: Validation loss: 1.8480111360549927\n",
            "1.5812775 Iteration 750: Validation loss: 1.6493785381317139\n",
            "1.4629028 Iteration 1000: Validation loss: 1.5552294254302979\n",
            "1.3523409 Iteration 1250: Validation loss: 1.5148968696594238\n",
            "1.347347 Iteration 1500: Validation loss: 1.4818370342254639\n",
            "1.324385 Iteration 1750: Validation loss: 1.4734055995941162\n",
            "1.3026986 Iteration 2000: Validation loss: 1.4473998546600342\n",
            "1.2757719 Iteration 2250: Validation loss: 1.4485535621643066\n"
          ]
        }
      ],
      "source": [
        "@partial(jax.jit, static_argnums=(3,))\n",
        "def loss_fn(params, batch, key, train):\n",
        "    x, y = batch\n",
        "    logits = m.apply(params, x, rngs={\"dropout\": key}, deterministic=not train)\n",
        "    loss = jnp.mean(\n",
        "        optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y)\n",
        "    )\n",
        "    return loss\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update(params, opt_state, batch, key):\n",
        "    loss, grad = jax.value_and_grad(loss_fn)(params, batch, key, True)\n",
        "    updates, opt_state = opt.update(grad, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state, loss\n",
        "\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "data_key = jax.random.PRNGKey(0)\n",
        "drop_key = jax.random.PRNGKey(1)\n",
        "\n",
        "# iterate over the batches, for 40 epochs\n",
        "for i, batch in enumerate(dataset(data_key, train, 256, 64, len(train) * 40)):\n",
        "    drop_key = jax.random.fold_in(drop_key, i)\n",
        "    params, opt_state, trn_loss = update(params, opt_state, batch, d_key)\n",
        "\n",
        "    # every 250 steps, compute the validation loss\n",
        "    if i % 250 == 0:\n",
        "        losses = []\n",
        "        for test_batch in dataset(data_key, test, 256, 256, len(test)*2):\n",
        "            losses.append(float(loss_fn(params, test_batch, drop_key, False)))\n",
        "\n",
        "        loss = jnp.mean(jnp.array(losses))\n",
        "        all_losses.append([i, loss])\n",
        "        print(trn_loss, f\"Iteration {i}: Validation loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow-sBwWmcr_0"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIQzLiCUnzLk"
      },
      "outputs": [],
      "source": [
        "completion_length = 200\n",
        "prompt = \"And therefore, \"\n",
        "\n",
        "prompt_tokens = jnp.array([char2idx[c] for c in prompt])\n",
        "start_idx = len(prompt_tokens) - 1\n",
        "prompt_tokens = jnp.pad(prompt_tokens, (0, 256 - len(prompt_tokens)), mode=\"constant\")[None, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlzAZyd8f56G"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def prefill(params, prompt_tokens, idxs):\n",
        "    _, cache = m.apply(\n",
        "        params,\n",
        "        prompt_tokens,\n",
        "        mode=\"prefill\",\n",
        "        mutable=[\"cache\"],\n",
        "        deterministic=True,\n",
        "        idxs=idxs,\n",
        "    )\n",
        "\n",
        "    return cache[\"cache\"]\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def sample_token(key, params, cache, current_token):\n",
        "    logits, cache = m.apply(\n",
        "        {\"params\": params[\"params\"], \"cache\": cache},\n",
        "        current_token,\n",
        "        mode=\"decode\",\n",
        "        mutable=[\"cache\"],\n",
        "        deterministic=True,\n",
        "    )\n",
        "    cache = cache[\"cache\"]\n",
        "    next_token = jax.random.categorical(key, logits).astype(jnp.int32)\n",
        "\n",
        "    return next_token, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xl4DSc5cr_1",
        "outputId": "ac49068a-43ed-471b-f40f-13e5d6f15e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "And therefore, bastard Marcius?\n",
            "\n",
            "LEONTES:\n",
            "Because the princes and leave the sun's hour shadows I\n",
            "and a battle. What awe music?\n",
            "\n",
            "COMINIUS:\n",
            "Desay to your friend, I am a mile England.\n",
            "\n",
            "ISABELLA:\n",
            "The ginss of young of t\n"
          ]
        }
      ],
      "source": [
        "# Prefill the cache\n",
        "cache = prefill(params, prompt_tokens, jnp.array([start_idx - 1]))\n",
        "\n",
        "# Then, decode!\n",
        "sampling_key = jax.random.PRNGKey(1)\n",
        "current_token = prompt_tokens[:, start_idx : start_idx + 1]\n",
        "completion = prompt\n",
        "\n",
        "for i in range(completion_length):\n",
        "    sampling_key = jax.random.fold_in(sampling_key, i)\n",
        "    current_token, cache = sample_token(sampling_key, params, cache, current_token)\n",
        "    completion += idx2char[int(current_token[0, 0])]\n",
        "\n",
        "print(completion)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
